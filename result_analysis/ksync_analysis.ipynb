{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "from metrics import print_overall_performance_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8487b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5\n",
    "alpha = 1\n",
    "seeds = [10, 20, 30, 40, 50]\n",
    "upset_choices = ['upset', 'cycle inconsistency']\n",
    "MSE_choices = ['MSE']\n",
    "selected_metrics = MSE_choices + upset_choices\n",
    "METRICS_NUM = len(selected_metrics)\n",
    "baselines = ['spectral', 'row_norm_spectral', 'trivial']\n",
    "NUM_BASELINES = len(baselines)\n",
    "NUM_UPSET_CHOICES = len(upset_choices)\n",
    "NUM_MSE_CHOICES = len(MSE_choices)\n",
    "GNN_selection_choices = ['lr', 'train with', 'upset coeff', 'spectral coeff', 'row norm spectral coeff', 'cycle coeff', 'baseline']\n",
    "GNN_selection_choices_curr = ['train with', 'upset coeff', 'spectral coeff', 'row norm spectral coeff', 'cycle coeff', 'baseline']\n",
    "GNN_CHOICES_NUM = len(GNN_selection_choices)\n",
    "GNN_CHOICES_NUM_CURR = len(GNN_selection_choices_curr)\n",
    "all_GNNs = ['GNNSync']\n",
    "train_with_list = ['innerproduct']\n",
    "\n",
    "GNN_variant_names = train_with_list\n",
    "GNN_NUM = 1\n",
    "\n",
    "def generate_method_str_and_compare_names_all(all_methods=baselines):\n",
    "    method_str = ''\n",
    "    for method_name in all_methods:\n",
    "        method_str += method_name\n",
    "    compare_names_all = []\n",
    "    for method_name in all_methods:\n",
    "        if method_name not in ['DIGRAC', 'ib', 'DIGRAC_Att']:\n",
    "            compare_names_all.append(method_name)\n",
    "        else:\n",
    "            for GNN_type in GNN_variant_names:\n",
    "                compare_names_all.append(method_name+'_'+GNN_type)\n",
    "    return method_str, compare_names_all\n",
    "\n",
    "'''\n",
    "methods_of_interest = ['0001', '1000', '1001'] + baselines\n",
    "methods_of_interest_print = ['GNNSync-cycle', 'GNNSync-upset', 'GNNSync-sum', 'Spectral', 'Spectral_RN', 'Trivial']\n",
    "\n",
    "\n",
    "# below for linear comb ablation study\n",
    "baselines = ['trivial']\n",
    "methods_of_interest = ['0.0', '0.1', '0.3', '0.5', '0.7', '0.9', '1000'] + baselines\n",
    "methods_of_interest_print = [r'$\\tau=0.0$ (GNNSync-cycle)', r'$\\tau=0.1$', r'$\\tau=0.3$', r'$\\tau=0.5$', r'$\\tau=0.7$', r'$\\tau=0.9$', 'GNNSync-upset', 'Trivial']\n",
    "'''\n",
    "# below for ablation study\n",
    "baselines = ['trivial']\n",
    "methods_of_interest = ['0001', '0001g', '00012', '0001h', '0001t', '0001s'] + baselines\n",
    "methods_of_interest_print = ['Default', 'No Projected Gradient Steps', 'Not End-to-End', r'Separate $\\{\\mathbf{H}^{(l)}\\}$', r'Trainable $\\{\\alpha_\\gamma\\}$', '\"Spectral\" for Input Features', 'Trivial']\n",
    "\n",
    "\n",
    "innerproduct_ind = [0]\n",
    "INNERPRODUCT_GNN_NUM = len(innerproduct_ind)\n",
    "innerproduct_bool = np.zeros(GNN_NUM, dtype=bool)\n",
    "for i in innerproduct_ind:\n",
    "    innerproduct_bool[i] = True\n",
    "\n",
    "GNN_names_innerproduct = ['DIGRAC_innerproduct']\n",
    "\n",
    "\n",
    "compare_names_all = methods_of_interest\n",
    "METHODS_NUM = len(compare_names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list_dict = {}\n",
    "eta_list_dict = {}\n",
    "outlier_style_list_dict = {}\n",
    "N_list_dict = {}\n",
    "for dataset_name in ['ERO', 'BAO', 'RGGO']:\n",
    "    N_list_dict[dataset_name] = [360]\n",
    "    p_list_dict[dataset_name] = [0.05, 0.1, 0.15]\n",
    "    eta_list_dict[dataset_name] = {}\n",
    "    eta_list_dict[dataset_name][0.05] = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    eta_list_dict[dataset_name][0.1] = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    eta_list_dict[dataset_name][0.15] = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    outlier_style_list_dict[dataset_name] = ['multi_normal0', 'multi_normal1','gamma', 'block_normal6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5458af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_save_name(dataset='ERO/p5N360eta0styleuniform_bisync', all_methods=all_GNNs, train_with='dist', upset_coeff=1.0, spectral_coeff=1.0, row_norm_spectral_coeff=1.0,\n",
    "                           lr=0.01, hidden=8, num_trials=10, train_ratio=1, test_ratio=1,  AllTrain=True, sync_baseline='spectral', sigma=1.0, cycle_coeff=1, trainable_alpha=False, \n",
    "                           spectral_step_num=5, two_step=False, same_H=False, no_reg=True):\n",
    "    default_name_base = ''\n",
    "    if 'GNNSync' in all_methods:\n",
    "        default_name_base += 'dropout' + str(int(100*dropout))\n",
    "        default_name_base += 'upset_coe' + str(int(100*upset_coeff)) + 'cycle_coe' + str(int(100*cycle_coeff))\n",
    "        if cycle_coeff > 0 and not no_reg:\n",
    "            default_name_base += 'reg_coe100'\n",
    "        if spectral_step_num > 0:\n",
    "            default_name_base += 'spectral_step_num' + str(spectral_step_num) + 'alpha100train_alpha' + str(trainable_alpha)\n",
    "            if not same_H:\n",
    "                default_name_base += 'separate_graphs'\n",
    "        default_name_base += 'hid' + str(hidden) + 'lr' + str(int(1000*lr))\n",
    "        default_name_base += 'use' + str(sync_baseline) + 'SGD'\n",
    "\n",
    "    default_name_base +=  'trials' + str(num_trials)\n",
    "    if dataset[:3] in ['ERO', 'BAO', 'SBM', 'RGG'] and set(seeds) != set([10, 20, 30, 40, 50]):\n",
    "        default_name_base += 'seeds' + '_'.join([str(value) for value in np.array(seeds).flatten()])\n",
    "    if two_step:\n",
    "        default_name_base = 'two_step_' + default_name_base\n",
    "    return default_name_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_name_preprocess(dataset, p=0.05, outlier_style='uniform', eta=0.1, N=360, k=2, size_ratio=1, prob_ratio=2):\n",
    "    if dataset[-1]!='/':\n",
    "        dataset += '/'\n",
    "\n",
    "    if dataset[:3] in ['ERO', 'BAO', 'RGG']:\n",
    "        hidden = 8\n",
    "        default_name_base = 'p' + str(int(100*p)) + 'N' + str(N)\n",
    "        default_name_base += 'eta' + str(int(100*eta)) + 'style' + str(outlier_style)\n",
    "        if dataset[:4] == 'RGGO':\n",
    "            dataset = 'RGGO/' + default_name_base\n",
    "            if outlier_style == 'gamma' and N == 360:\n",
    "                dataset_print = 'RGGO(k={}, p={}, $\\eta$={})'.format(k, p, eta)\n",
    "            else:\n",
    "                dataset_print = 'RGGO(k={}, p={}, style={},$\\eta$={})'.format(k, p, outlier_style, eta)   \n",
    "        else:\n",
    "            dataset = dataset[:3] + '/' + default_name_base\n",
    "            if outlier_style == 'gamma' and N == 360:\n",
    "                dataset_print = dataset[:3] + '(k={}, p={}, $\\eta$={})'.format(k, p, eta)\n",
    "            else:\n",
    "                dataset_print = dataset[:3] + '(k={}, p={}, style={},$\\eta$={})'.format(k, p, outlier_style, eta)\n",
    "    dataset += 'k' + str(k)\n",
    "    dataset_print = str(k) + '&' + str(p) + '&' + str(eta) # updated for new table generation\n",
    "    \n",
    "    return dataset_print, dataset, hidden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.005]\n",
    "sync_baseline_list = ['row_norm_spectral', 'spectral']\n",
    "upset_coeff_list = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "spectral_coeff_list = [0]\n",
    "row_norm_spectral_coeff_list = [0]\n",
    "cycle_coeff_list = [0, 1]\n",
    "innerproduct_ind_correspondence_dict = {}\n",
    "\n",
    "i = 0\n",
    "for lr_ind, lr in enumerate(lr_list):\n",
    "    for train_ind, train_with in enumerate(train_with_list):\n",
    "        for upset_coeff_ind, upset_coeff in enumerate(upset_coeff_list):\n",
    "            for spectral_coeff_ind, spectral_coeff in enumerate(spectral_coeff_list):\n",
    "                for row_norm_spectral_coeff_ind, row_norm_spectral_coeff in enumerate(row_norm_spectral_coeff_list):\n",
    "                    for cycle_coeff_ind, cycle_coeff in enumerate(cycle_coeff_list):\n",
    "                        for base_ind, sync_baseline in enumerate(sync_baseline_list):\n",
    "                            for method_ind in range(INNERPRODUCT_GNN_NUM):\n",
    "                                innerproduct_ind_correspondence_dict[i] = [lr_ind, train_ind, upset_coeff_ind, spectral_coeff_ind, \\\n",
    "                                                                row_norm_spectral_coeff_ind, cycle_coeff_ind, base_ind, method_ind]\n",
    "                                i += 1\n",
    "                            \n",
    "innerproduct_cases_num = len(innerproduct_ind_correspondence_dict.keys())\n",
    "print(innerproduct_cases_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNN_load_results(dataset, all_methods=all_GNNs, train_with='innerproduct', \n",
    "                                   upset_coeff=1, spectral_coeff=1, row_norm_spectral_coeff=1, lr=0.01, hidden=32, num_trials=10, \n",
    "                                   train_ratio=0.8, test_ratio=0.1,  AllTrain=True, sync_baseline='spectral', \n",
    "                                   sigma=1, cycle_coeff=1, trainable_alpha=False, spectral_step_num=5, two_step=False, same_H=False, no_reg=True):\n",
    "    save_name = generate_save_name(dataset=dataset, all_methods=all_GNNs, train_with=train_with, \n",
    "                                   upset_coeff=upset_coeff, spectral_coeff=spectral_coeff, row_norm_spectral_coeff=row_norm_spectral_coeff,\n",
    "                                   lr=lr, hidden=hidden, num_trials=num_trials, train_ratio=train_ratio, test_ratio=test_ratio, \n",
    "                                    AllTrain=AllTrain, sync_baseline=sync_baseline, sigma=sigma, cycle_coeff=cycle_coeff, trainable_alpha=trainable_alpha, \n",
    "                                    spectral_step_num=spectral_step_num, two_step=two_step, same_H=same_H, no_reg=no_reg)\n",
    "    method_str, _ = generate_method_str_and_compare_names_all(all_methods)\n",
    "    dir_name = '../result_arrays/'+dataset\n",
    "    try:\n",
    "        mse_res = np.load(os.path.join(dir_name,'MSE',method_str,save_name) + '.npy')[:, :, 2]\n",
    "        final_upset = np.load(os.path.join(dir_name,'upset',method_str,save_name) + '.npy')\n",
    "    except FileNotFoundError:\n",
    "        print('File not found: ', os.path.join(dir_name,'MSE',method_str,save_name))\n",
    "    return mse_res, final_upset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b38600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNN_selection(dataset, train_ratio, test_ratio, AllTrain, hidden, num_trials, constraint=None):\n",
    "    pretrain_epochs = 50\n",
    "    sigma = 1\n",
    "    full_results_innerproduct = 1000*np.ones((METRICS_NUM, INNERPRODUCT_GNN_NUM * innerproduct_cases_num))\n",
    "    final_ind_innerproduct = 0\n",
    "    trainable_alpha = False\n",
    "    has_result = False\n",
    "    two_step = False\n",
    "    same_H = True\n",
    "    no_reg = True\n",
    "    spectral_step_num = 5\n",
    "    for lr_ind, lr in enumerate(lr_list):\n",
    "        for train_ind, train_with in enumerate(train_with_list):\n",
    "            for upset_coeff_ind, upset_coeff in enumerate(upset_coeff_list):\n",
    "                for spectral_coeff_ind, spectral_coeff in enumerate(spectral_coeff_list):\n",
    "                    for row_norm_spectral_coeff_ind, row_norm_spectral_coeff in enumerate(row_norm_spectral_coeff_list):\n",
    "                        for cycle_coeff_ind, cycle_coeff in enumerate(cycle_coeff_list):\n",
    "                            for base_ind, sync_baseline in enumerate(sync_baseline_list):\n",
    "                                try:\n",
    "                                    if constraint == 'row_norm_spectral':\n",
    "                                        assert upset_coeff == 1 and spectral_coeff == 0 and row_norm_spectral_coeff == 0 and cycle_coeff == 0 and sync_baseline == 'row_norm_spectral'\n",
    "                                    elif constraint == 'spectral':\n",
    "                                        assert upset_coeff == 1 and spectral_coeff == 0 and row_norm_spectral_coeff == 0 and cycle_coeff == 0 and sync_baseline == 'spectral'\n",
    "                                    elif constraint == 'trainable_alpha':\n",
    "                                        assert upset_coeff == 1 and spectral_coeff == 0 and row_norm_spectral_coeff == 0 and cycle_coeff == 0 and sync_baseline == 'row_norm_spectral'\n",
    "                                        trainable_alpha = True\n",
    "                                    elif constraint == 'no_GPM_steps':\n",
    "                                        assert upset_coeff == 0 and spectral_coeff == 0 and row_norm_spectral_coeff == 0 and cycle_coeff == 1 and sync_baseline == 'row_norm_spectral'\n",
    "                                        spectral_step_num = 0\n",
    "                                    elif constraint == 'two_step':\n",
    "                                        assert upset_coeff == 0 and spectral_coeff == 0 and row_norm_spectral_coeff == 0 and cycle_coeff == 1 and sync_baseline == 'row_norm_spectral'\n",
    "                                        spectral_step_num = 0\n",
    "                                        two_step = True\n",
    "                                    elif constraint == 'two_step_separate_H':\n",
    "                                        assert upset_coeff == 0 and spectral_coeff == 0 and row_norm_spectral_coeff == 0 and cycle_coeff == 1 and sync_baseline == 'row_norm_spectral'\n",
    "                                        spectral_step_num = 0\n",
    "                                        two_step = True\n",
    "                                        same_H = False\n",
    "                                    elif constraint == 'separate_H':\n",
    "                                        assert upset_coeff == 0 and spectral_coeff == 0 and row_norm_spectral_coeff == 0 and cycle_coeff == 1 and sync_baseline == 'row_norm_spectral'\n",
    "                                        same_H = False\n",
    "                                    elif constraint == 'no_reg':\n",
    "                                        assert sync_baseline == 'row_norm_spectral' and upset_coeff == 0 and cycle_coeff == 1.0\n",
    "                                        no_reg = True\n",
    "                                    if len(constraint) == 3:\n",
    "                                        assert sync_baseline == 'row_norm_spectral' and upset_coeff == float(constraint) and cycle_coeff == 1.0\n",
    "                                    elif len(constraint) == 4:\n",
    "                                        assert sync_baseline == 'row_norm_spectral' and upset_coeff == float(constraint[0]) and spectral_coeff == float(constraint[1]) and row_norm_spectral_coeff == float(constraint[2]) and cycle_coeff == float(constraint[3])\n",
    "                                    elif len(constraint) == 5:\n",
    "                                        assert upset_coeff == float(constraint[0]) and spectral_coeff == float(constraint[1]) and row_norm_spectral_coeff == float(constraint[2]) and cycle_coeff == float(constraint[3])\n",
    "                                        if constraint[4] == 's':\n",
    "                                            assert sync_baseline == 'spectral'\n",
    "                                        elif constraint[4] == 't':\n",
    "                                            assert sync_baseline == 'row_norm_spectral'\n",
    "                                            trainable_alpha = True\n",
    "                                        elif constraint[4] == 'h':\n",
    "                                            assert sync_baseline == 'row_norm_spectral'\n",
    "                                            same_H = False\n",
    "                                        elif constraint[4] == 'g': # no GPM steps\n",
    "                                            assert sync_baseline == 'row_norm_spectral'\n",
    "                                            spectral_step_num = 0\n",
    "                                        elif constraint[4] == '2': # two steps\n",
    "                                            assert sync_baseline == 'row_norm_spectral'\n",
    "                                            spectral_step_num = 0\n",
    "                                            two_step = True\n",
    "                                        elif constraint[4] == 'w': # two steps and separate H\n",
    "                                            assert sync_baseline == 'row_norm_spectral'\n",
    "                                            spectral_step_num = 0\n",
    "                                            two_step = True\n",
    "                                            same_H = False\n",
    "                                    \n",
    "                                    # print('1', upset_coeff, cycle_coeff)\n",
    "                                    mse, upsets = GNN_load_results(dataset=dataset, all_methods=all_GNNs, train_with=train_with, \n",
    "                                            upset_coeff=upset_coeff, spectral_coeff=spectral_coeff, row_norm_spectral_coeff=row_norm_spectral_coeff, \n",
    "                                            lr=lr, hidden=hidden, num_trials=num_trials, train_ratio=train_ratio, test_ratio=test_ratio, \n",
    "                                            AllTrain=AllTrain, sync_baseline=sync_baseline, sigma=sigma, cycle_coeff=cycle_coeff, \n",
    "                                            trainable_alpha=trainable_alpha, spectral_step_num=spectral_step_num, two_step=two_step, same_H=same_H, no_reg=no_reg)\n",
    "\n",
    "                                    mean_mse = np.nanmean(mse[innerproduct_bool].swapaxes(0,-1), axis=1)\n",
    "                                    full_results_innerproduct[:NUM_MSE_CHOICES, final_ind_innerproduct: final_ind_innerproduct + INNERPRODUCT_GNN_NUM] = mean_mse\n",
    "\n",
    "\n",
    "                                    mean_upsets = upsets[innerproduct_bool].swapaxes(0,-1).mean(axis=1)\n",
    "                                    full_results_innerproduct[NUM_MSE_CHOICES:, final_ind_innerproduct: final_ind_innerproduct + INNERPRODUCT_GNN_NUM] = mean_upsets\n",
    "\n",
    "                                    has_result = True\n",
    "                                except FileNotFoundError:\n",
    "                                    pass\n",
    "                                except AssertionError:\n",
    "                                    pass\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "                                final_ind_innerproduct += INNERPRODUCT_GNN_NUM\n",
    "    if has_result:\n",
    "        best_ind = np.zeros((METRICS_NUM, 1))\n",
    "        best_vals = np.ones((METRICS_NUM, 1))\n",
    "        best_vals[:] = np.nan\n",
    "        full_results_innerproduct = np.nan_to_num(full_results_innerproduct, nan=1000)\n",
    "        if dataset[:3] in ['ERO', 'BAO', 'SBM', 'RGG']:\n",
    "            for mse_ind in range(NUM_MSE_CHOICES):\n",
    "                best_ind[mse_ind, 0] = full_results_innerproduct[mse_ind].argmin()\n",
    "                best_vals[mse_ind, 0] = np.nanmin(full_results_innerproduct[mse_ind])\n",
    "        \n",
    "\n",
    "        for upset_ind in range(NUM_UPSET_CHOICES):\n",
    "            best_vals[NUM_MSE_CHOICES+upset_ind, 0] = np.nanmin(full_results_innerproduct[NUM_MSE_CHOICES+upset_ind])\n",
    "            best_ind[NUM_MSE_CHOICES+upset_ind, 0] = full_results_innerproduct[NUM_MSE_CHOICES+upset_ind].argmin()\n",
    "        selected_indices = np.zeros((METRICS_NUM, 1, GNN_CHOICES_NUM+1))\n",
    "        mse_res = np.zeros((METRICS_NUM, 1, 10, NUM_MSE_CHOICES))\n",
    "        mse_res[:] = np.nan\n",
    "        final_upset = np.zeros((METRICS_NUM, 1, 10, NUM_UPSET_CHOICES)) # the first \"2\" means dist and innerproduct\n",
    "        final_upset[:] = np.nan\n",
    "        for i in range(METRICS_NUM):\n",
    "            j = 0\n",
    "            selected_indices[i, j] = innerproduct_ind_correspondence_dict[best_ind[i, j]]\n",
    "                \n",
    "            lr = lr_list[int(selected_indices[i, j, 0])]\n",
    "            train_with = train_with_list[int(selected_indices[i, j, 1])]\n",
    "            upset_coeff = upset_coeff_list[int(selected_indices[i, j, 2])]\n",
    "            spectral_coeff = spectral_coeff_list[int(selected_indices[i, j, 3])]\n",
    "            row_norm_spectral_coeff = row_norm_spectral_coeff_list[int(selected_indices[i, j, 4])]\n",
    "            cycle_coeff = cycle_coeff_list[int(selected_indices[i, j, 5])]\n",
    "            sync_baseline = sync_baseline_list[int(selected_indices[i, j, 6])]\n",
    "\n",
    "            sel_ind = int(selected_indices[i, j, -1])\n",
    "            GNN_selected = GNN_names_innerproduct[sel_ind]\n",
    "            selected_vals = [lr, train_with, upset_coeff, spectral_coeff,\\\n",
    "                            row_norm_spectral_coeff, sync_baseline, pretrain_epochs]\n",
    "            print_str = GNN_selected + ' on ' + dataset + ': '\n",
    "            for k in range(GNN_CHOICES_NUM):\n",
    "                print_str += GNN_selection_choices[k] + '=' + str(selected_vals[k]) + ', '\n",
    "            print_str += 'for the best ' + selected_metrics[i]\n",
    "            mse, upsets = GNN_load_results(dataset=dataset, all_methods=all_GNNs, train_with=train_with, \n",
    "                                        upset_coeff=upset_coeff, spectral_coeff=spectral_coeff, row_norm_spectral_coeff=row_norm_spectral_coeff, \n",
    "                                        lr=lr, hidden=hidden, num_trials=num_trials, train_ratio=train_ratio, test_ratio=test_ratio, \n",
    "                                        AllTrain=AllTrain, sync_baseline=sync_baseline, sigma=sigma, cycle_coeff=cycle_coeff, \n",
    "                                        trainable_alpha=trainable_alpha, spectral_step_num=spectral_step_num, two_step=two_step, same_H=same_H, no_reg=no_reg)\n",
    "\n",
    "            mse_res[i, j] = (mse[innerproduct_bool])[sel_ind]\n",
    "            upsets_res = (upsets[innerproduct_bool])[sel_ind]\n",
    "            final_upset[i, j] = np.array(upsets_res)\n",
    "        return mse_res, final_upset, selected_indices\n",
    "    else:\n",
    "        raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_results(dataset, upset_coeff=1.0, p=0.1, \n",
    "                       AllTrain=True, eta=0.1, lr=0.05, hidden=8, \n",
    "                        N=350, outlier_style='gamma', train_ratio = 0.8, test_ratio = 0.1, dropout=0.5, sigma=1.0, k=2,\n",
    "                           methods_of_interest=methods_of_interest):\n",
    "    num_trials = 2\n",
    "    alpha = 1\n",
    "    seeds = [10, 20, 30, 40, 50]\n",
    "    \n",
    "    dataset_print, dataset, hidden = dataset_name_preprocess(dataset, p, outlier_style, eta, N, k)\n",
    "\n",
    "    if dataset[:3] not in ['ERO', 'BAO', 'RGG']:\n",
    "        num_trials = 10\n",
    "        AllTrain = True\n",
    "        train_ratio = 1\n",
    "        test_ratio = 1\n",
    "        seeds = [10]\n",
    "    \n",
    "    final_upset_full_list_dist = []\n",
    "    mse_res_full_list_innerproduct = []\n",
    "    final_upset_full_list_innerproduct = []\n",
    "    for ind, constraint in enumerate(methods_of_interest):\n",
    "        if ind < len(methods_of_interest)-len(baselines):\n",
    "            mse_res_full, final_upset_full, selected_indices = GNN_selection(dataset, train_ratio, test_ratio, AllTrain, hidden, num_trials, constraint=constraint)\n",
    "            mse_res_full_list_innerproduct.append(mse_res_full)\n",
    "            final_upset_full_list_innerproduct.append(final_upset_full)\n",
    "        \n",
    "\n",
    "\n",
    "    mse_res_all = np.zeros((METRICS_NUM, METHODS_NUM, num_trials*len(seeds), NUM_MSE_CHOICES))\n",
    "    mse_res_all[:] = np.nan\n",
    "    final_upset_all = np.zeros((METRICS_NUM, METHODS_NUM, num_trials*len(seeds), NUM_UPSET_CHOICES))\n",
    "    final_upset_all[:] = np.nan\n",
    "    dir_name = '../result_arrays/'+dataset\n",
    "    for i in range(METRICS_NUM):\n",
    "        compare_names_all = methods_of_interest\n",
    "        mse_res = mse_res_full_list_innerproduct[0][i]\n",
    "        final_upset = final_upset_full_list_innerproduct[0][i]\n",
    "        for j in np.arange(1, len(methods_of_interest)-len(baselines)):\n",
    "            mse_res = np.concatenate((mse_res, mse_res_full_list_innerproduct[j][i]), axis=0)\n",
    "            final_upset = np.concatenate((final_upset, final_upset_full_list_innerproduct[j][i]), axis=0)\n",
    "\n",
    "\n",
    "        # include baseline results\n",
    "        compare_names_baselines = []\n",
    "        for baseline in baselines:\n",
    "            save_name = generate_save_name(dataset=dataset, all_methods=[baseline], num_trials=num_trials, \n",
    "                                        train_ratio=train_ratio, test_ratio=test_ratio,  AllTrain=AllTrain)\n",
    "            method_str, compare_names_baselines = generate_method_str_and_compare_names_all([baseline])\n",
    "            try:\n",
    "                mse_res = np.concatenate((mse_res, np.load(os.path.join(dir_name,'MSE',method_str,save_name) + '.npy')[:, :, 2]), axis=0)\n",
    "                final_upset = np.concatenate((final_upset, np.load(os.path.join(dir_name,'upset',method_str,save_name) + '.npy')), axis=0)\n",
    "                compare_names_baselines.append(baseline)\n",
    "            except FileNotFoundError:\n",
    "                print(os.path.join(dir_name,'MSE',method_str,save_name) + '.npy')\n",
    "            except ValueError:\n",
    "                print(os.path.join(dir_name,'MSE',method_str,save_name) + '.npy ValueError!')\n",
    "        compare_names_all =  compare_names_all + compare_names_baselines\n",
    "\n",
    "        \n",
    "        mse_res_all[i] = mse_res\n",
    "        final_upset_all[i] = final_upset\n",
    "        \n",
    "    return dataset_print, mse_res_all, final_upset_all, compare_names_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37391c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_results(dataset='ERO', outlier_style='gamma'):\n",
    "    dataset_name_full = []\n",
    "    mse_res_all_full = []\n",
    "    final_upset_all_full = []\n",
    "    for k in [2, 3, 4]:\n",
    "        for p in p_list_dict[dataset]:\n",
    "            for eta in eta_list_dict[dataset][p]:\n",
    "                for N in N_list_dict[dataset]:\n",
    "                    try:\n",
    "                        dataset_long, mse_res_all, final_upset_all, _ = extract_results(dataset=dataset, \n",
    "                            p=p, eta=eta, outlier_style=outlier_style, N=N, k=k)\n",
    "                        dataset_name_full.append(dataset_long)\n",
    "                        mse_res_all_full.append(mse_res_all)\n",
    "                        final_upset_all_full.append(final_upset_all)\n",
    "                    except FileNotFoundError:\n",
    "                        print('No result yet for {}, p={}, eta={}, outlier style = {}, N = {}, k={}.'.format(dataset,\n",
    "                            p, eta, outlier_style, N, k))\n",
    "\n",
    "\n",
    "    full_results = np.concatenate((np.array(mse_res_all_full), np.array(final_upset_all_full)), axis=-1)\n",
    "    for i in range(METRICS_NUM):\n",
    "        for j in range(METRICS_NUM):\n",
    "            if i == 0 and j == 0:\n",
    "                results_to_print = full_results[:,j,:,:,i].swapaxes(0,2)\n",
    "                if not np.isnan(results_to_print).all():\n",
    "                    dataset_name_print = dataset_name_full\n",
    "                    compare_names_print = compare_names_all\n",
    "                    title_name = selected_metrics[i] + ' with best ' + selected_metrics[j] + ' on ' + dataset + '_' + outlier_style\n",
    "                    print_overall_performance_mean_std(title_name, results_to_print, \n",
    "                                    compare_names_print, dataset_name_print, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af519b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_results('BAO', 'multi_normal0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca564fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save = True\n",
    "figure_markers = ['*','P','<','s','8','+','H','.','D','>','v','^','d']\n",
    "compare_names_all = methods_of_interest_print \n",
    "for k in [2, 3, 4]:\n",
    "    for outlier_style in ['multi_normal0', 'multi_normal1','gamma', 'block_normal6']:\n",
    "        for dataset in ['ERO', 'BAO', 'RGGO']:\n",
    "            for p in p_list_dict[dataset]:\n",
    "                change_var_values = np.array(eta_list_dict[dataset][p])\n",
    "                dataset_name_full = []\n",
    "                mse_res_all_full = []\n",
    "                final_upset_all_full = []\n",
    "                change_var_values_list = []\n",
    "                for eta in change_var_values:\n",
    "                    try:\n",
    "                        dataset_long, mse_res_all, final_upset_all, _ = extract_results(dataset=dataset, \n",
    "                            p=p, eta=eta, outlier_style=outlier_style, N=360, k=k)\n",
    "                        dataset_name_full.append(dataset_long)\n",
    "                        mse_res_all_full.append(mse_res_all)\n",
    "                        final_upset_all_full.append(final_upset_all)\n",
    "                        change_var_values_list.append(eta)\n",
    "                    except FileNotFoundError:\n",
    "                        print('No result yet for {}, p={}, eta={}.'.format(dataset,\n",
    "                            p, eta))\n",
    "                change_var_values = np.array(change_var_values_list)\n",
    "                mse_res_all = np.array(mse_res_all_full)[:, 0, :, :, 0] # dim 0 is eta dim, dim 1 is method dim, dim 2 is 10 runs\n",
    "                mse_res_mean = np.mean(mse_res_all, axis=2)\n",
    "                mse_res_std = np.std(mse_res_all, axis=2)\n",
    "                results_mean = mse_res_mean.transpose()\n",
    "                results_std = mse_res_std.transpose()\n",
    "                plt.figure(figsize=[8,6])\n",
    "                plt.rcParams.update({'font.size': 12})\n",
    "                plt.xticks(np.arange(change_var_values.min(), change_var_values.max()+0.1, step=0.1))\n",
    "                for j in range(len(compare_names_all)-len(baselines)):\n",
    "                    plt.errorbar(change_var_values, results_mean[j], yerr=results_std[j], label=compare_names_all[j],alpha=0.8, fmt=figure_markers[j%len(figure_markers)], ls='--')\n",
    "                for j in range(len(compare_names_all)-len(baselines), len(compare_names_all)):\n",
    "                    plt.errorbar(change_var_values, results_mean[j], yerr=results_std[j], label=compare_names_all[j],alpha=0.7, fmt=figure_markers[j%len(figure_markers)], ls='None')\n",
    "                plt.xlabel(r'$\\eta$',fontsize=22)\n",
    "                plt.ylabel('MSE',fontsize=22, labelpad=-5)\n",
    "                plt.rcParams.update({'font.size': 12})    \n",
    "                title_name = 'k'+str(k)+dataset+'p'+str(int(100*p))+'N360style'+outlier_style\n",
    "                plt.title(title_name)\n",
    "                if save:\n",
    "                    print('Saving figure!')\n",
    "                    save_name = '../ksync_ablation_plots/k'+str(k)+dataset+'p'+str(int(100*p))+'N360style'+outlier_style+'.pdf'\n",
    "                    plt.savefig(save_name,format='pdf')\n",
    "                if dataset == 'ERO' and p == 0.05:\n",
    "                    plt.legend(framealpha=0.0,fontsize=15,loc='lower left', ncol=4, bbox_to_anchor=(0, -0.4))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcd84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fea18b2a1a69a86b3315cc7cd2a706ccbb2eae9ae7d74e28b20efaca82a4aac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
